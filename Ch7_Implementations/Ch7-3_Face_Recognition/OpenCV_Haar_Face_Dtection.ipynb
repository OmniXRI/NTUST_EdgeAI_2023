{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "OpenCV_Haar_Face_Dtection.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 使用OpenCV Haar 聯級法偵測人臉及眼睛位置\n",
        "\n",
        "使用聯級法偵測速度極快，但正確率不佳，有很多干擾因素，包括人臉尺寸、歪斜、轉動、光影、部份重疊、複雜背景等。  \n",
        "參考資料來源：https://docs.opencv.org/4.1.2/db/d28/tutorial_cascade_classifier.html  \n",
        "歐尼克斯實境互動工作室 OmniXRI Jack, 2022.04.25整理製作  "
      ],
      "metadata": {
        "id": "ZLCVtyGuRu3m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. 檢查Colab已安裝套件（可略過）\n",
        "本範例主要需用到下列套件，Colab預設已安裝下列版本  \n",
        "opencv-python                 4.1.2.30  \n",
        "numpy                         1.21.6  \n",
        "requests                      2.23.0\n",
        "matplotlib                    3.2.2  \n",
        "可利用pip list指令進行檢查\n"
      ],
      "metadata": {
        "id": "ZDjao2aPR_rM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xwFtYffKRtni"
      },
      "outputs": [],
      "source": [
        "!pip list # 檢查python已安裝套件包（可略過）"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. 建立取得Webcam影像之程式碼片段\n",
        "可直接使用Colob選單左下方的程式碼片段（< >按鍵），點擊Camera Capture即可產生下面二段程式碼。  \n",
        "第一段定義 take_photo 取得Webcam影像Java Script程式碼片段。  \n",
        "第二段啟動Webcam並等待按下【Capture】鍵，完成取像並取名為photo.jpg。 "
      ],
      "metadata": {
        "id": "EhDcb8IDSVgD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "\n",
        "def take_photo(filename='photo.jpg', quality=0.8):\n",
        "  js = Javascript('''\n",
        "    async function takePhoto(quality) {\n",
        "      const div = document.createElement('div');\n",
        "      const capture = document.createElement('button');\n",
        "      capture.textContent = 'Capture';\n",
        "      div.appendChild(capture);\n",
        "\n",
        "      const video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "      document.body.appendChild(div);\n",
        "      div.appendChild(video);\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      // Resize the output to fit the video element.\n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "      // Wait for Capture to be clicked.\n",
        "      await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "      const canvas = document.createElement('canvas');\n",
        "      canvas.width = video.videoWidth;\n",
        "      canvas.height = video.videoHeight;\n",
        "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "      stream.getVideoTracks()[0].stop();\n",
        "      div.remove();\n",
        "      return canvas.toDataURL('image/jpeg', quality);\n",
        "    }\n",
        "    ''')\n",
        "  display(js)\n",
        "  data = eval_js('takePhoto({})'.format(quality))\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  with open(filename, 'wb') as f:\n",
        "    f.write(binary)\n",
        "  return filename"
      ],
      "metadata": {
        "id": "BHzLrMXzSw9L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "try:\n",
        "  filename = take_photo()\n",
        "  print('Saved to {}'.format(filename))\n",
        "  \n",
        "  # Show the image which was just taken.\n",
        "  display(Image(filename))\n",
        "except Exception as err:\n",
        "  # Errors will be thrown if the user does not have a webcam or if they do not\n",
        "  # grant the page permission to access it.\n",
        "  print(str(err))"
      ],
      "metadata": {
        "id": "f_r32uHrSw9P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. 讀入影像並轉換成灰階影像\n",
        "\n",
        "後續人臉及眼睛偵測的測試影像來源可以有下列幾種方式：  \n",
        "1.   使用前面Webcam取得之靜態影像\n",
        "2.   直接將影像上傳到虛擬機上\n",
        "3.   將影像置放於Google雲端硬碟上，再掛載到Colab進行讀取\n",
        "4.   使用網路(含Github)上公開的影像\n",
        "\n",
        "這裡以從Github上取得影像為例。\n",
        "1.   先使用requests.get()取得原始影像。若要從Github中取得影像時，需將原檔案路徑修改為原始檔型式。首先在Github原始影像上以滑鼠右鍵點擊，選擇「複製圖片鏈結」取得影像原始網址：\n",
        "https://github.com/OmniXRI/Colab_DevCloud_OpenVINO_Samples/blob/main/dataset/face_detection_01.jpg  \n",
        "接著修改後檔名：主要是將**github.com**變成**raw.githubusercontent.com**，把**/blob/main**改成**master**路徑名稱，其它子路徑保留   \n",
        "https://raw.githubusercontent.com/OmniXRI/Colab_DevCloud_OpenVINO_Samples/master/dataset/face_detection_01.jpg \n",
        "2.   再以cv2.imdecode把檔案格式改成OpenCV可以存取的影像檔格式。  \n",
        "3.   最後將影像寫入（儲存）到指定名稱的檔案中。  \n",
        "\n",
        "接著就可讀入彩色影像，轉成灰階格式，再顯示確認讀取成功。  \n"
      ],
      "metadata": {
        "id": "Qo72WP0DV87X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2 # 導入OpenCV套件包\n",
        "from google.colab.patches import cv2_imshow # 導入顯示OpenCV格式影像套件包\n",
        "import numpy as np # 導入numpy套件包\n",
        "import requests # 導入requests套件包\n",
        "\n",
        "## 亦可選擇從網路獲取一張影像，轉成OpenCV格式並存檔，檔名photo.jpg\n",
        "## 若選擇從網路上檔案來進行人臉辨識，則加入下面三行程式，否則加上註釋符號令其略過\n",
        "file = requests.get(\"https://raw.githubusercontent.com/OmniXRI/Colab_DevCloud_OpenVINO_Samples/master/dataset/face_detection_01.jpg\")\n",
        "img_s = cv2.imdecode(np.fromstring(file.content, np.uint8), 1)\n",
        "cv2.imwrite('photo.jpg',img_s)\n",
        "\n",
        "img = cv2.imread('photo.jpg') # 讀入影像\n",
        "gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) # 將影像轉為灰階格式\n",
        "cv2_imshow(gray_img) # 顯示輸入灰階影像"
      ],
      "metadata": {
        "id": "JdXzOQKmxtfu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. 建立聯級開始人臉偵測\n",
        "\n",
        "OpenCV提供了很多預訓練的人臉聯級(Cascade)檢測定義檔(xml)。一般在本地端有特定的存放路徑，在Colab虛擬機上則會放在 /usr/local/lib/python3.10/dist-packages/cv2/data/ 下，當找不到指定的xml檔案時會出現下列錯誤訊息。  \n",
        "error: OpenCV(4.1.2) /io/opencv/modules/objdetect/src/cascadedetect.cpp:1689: error: (-215:Assertion failed) !empty() in function 'detectMultiScale'  \n",
        "若仍不確定xml檔案所在路徑，則可使用下列指令來尋找。  \n",
        "!find / -iname \"haarcascade*\"  \n",
        "這裡僅先使用偵測正面人臉及眼睛的聯級定義來建立分類器，並偵測影像中共有多少人臉出現。  "
      ],
      "metadata": {
        "id": "UlrgbxzUxuWX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 宣告聯級檔案所在路徑及名稱\n",
        "path_face = \"/usr/local/lib/python3.10/dist-packages/cv2/data/haarcascade_frontalface_default.xml\" # 正面人臉預訓練聯級檔\n",
        "path_eyes = \"/usr/local/lib/python3.10/dist-packages/cv2/data/haarcascade_eye.xml\" # 眼睛預訓練聯級檔\n",
        "\n",
        "face_cascade = cv2.CascadeClassifier(path_face) # 建立人臉分類器\n",
        "eye_cascade  = cv2.CascadeClassifier(path_eyes) # 建立眼睛分類器\n",
        "\n",
        "faces = face_cascade.detectMultiScale(gray_img, scaleFactor=1.1, minNeighbors=4) # 偵測影像中所有人臉\n",
        "print(f\"{len(faces)} faces detected in the image.\") # 顯示偵測到的人臉數量"
      ],
      "metadata": {
        "id": "TcHt6O6FS_Ha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. 顯示人臉及眼睛位置\n",
        "\n",
        "這裡會依據前項偵測的人臉位置繪制綠色外框。再裁切人臉部份影像（ROI）進行眼睛偵測，繪製紅框，可減少誤判率。  \n"
      ],
      "metadata": {
        "id": "HWvWn8QVV725"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for x, y, w, h in faces:\n",
        "    cv2.rectangle(img, (x,y), (x+w, y+h), color=(0,255,0), thickness=2) # 繪制人臉綠色外框\n",
        "    \n",
        "    roi = img[y:y+h, x:x+w] # 取得人臉部份影像\n",
        "    roi_gray = gray_img[y:y+h, x:x+h] # 取得人臉部份灰階影像\n",
        "    eyes = eye_cascade.detectMultiScale(roi_gray) # 進行眼睛位置偵測\n",
        "    print(f\"{len(eyes)} eyes detected in the image.\") # 顯示偵測到的眼睛數量\n",
        "\n",
        "    for ex, ey, ew, eh in eyes:\n",
        "      cv2.rectangle(roi, (ex,ey), (ex+ew, ey+eh), color = (0,0,255), thickness=2) # 繪製眼睛紅色外框\n",
        "\n",
        "cv2_imshow(img) # 顯示結果影像"
      ],
      "metadata": {
        "id": "Dnmu0hVGVMNZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}